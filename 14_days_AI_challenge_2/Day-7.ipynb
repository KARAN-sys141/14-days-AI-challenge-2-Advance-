{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "048b0d49-c340-4bd7-bf39-570da823b15a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "silver_table_name = \"workspace.ecommerce.user_features_silver\"\n",
    "df_silver = spark.table(silver_table_name)\n",
    "\n",
    "df_features = df_silver.select(\"user_id\", \"total_views\", \"total_cart_adds\")\n",
    "df_labels = (\n",
    "    df_silver.select(\"user_id\", \"total_purchases\")\n",
    "    .withColumn(\"label\", when(col(\"total_purchases\") > 0, 1).otherwise(0))\n",
    "    .drop(\"total_purchases\")\n",
    ")\n",
    "\n",
    "df_model_ready = df_features.join(df_labels, on=\"user_id\", how=\"inner\")\n",
    "train_df, test_df = df_model_ready.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"total_views\", \"total_cart_adds\"], outputCol=\"features\")\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", seed=42)\n",
    "\n",
    "pipeline_lr = Pipeline(stages=[assembler, lr])\n",
    "pipeline_rf = Pipeline(stages=[assembler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "317b238d-d693-4109-8b16-0c55e69796be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "mlflow_temp_path = \"/Volumes/workspace/ecommerce/ecommerce_data/mlflow_tmp\"\n",
    "dbutils.fs.mkdirs(mlflow_temp_path) \n",
    "os.environ[\"MLFLOW_DFS_TMP\"] = mlflow_temp_path\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "# Logistic Regression\n",
    "with mlflow.start_run(run_name=\"Day7_Logistic_Regression\"):\n",
    "    model_lr = pipeline_lr.fit(train_df)\n",
    "    preds_lr = model_lr.transform(test_df)\n",
    "    auc_lr = evaluator.evaluate(preds_lr)\n",
    "    \n",
    "    # Logging Parameters & Metrics\n",
    "    mlflow.log_param(\"Model_Type\", \"Logistic Regression\")\n",
    "    mlflow.log_metric(\"AUC_Score\", auc_lr)\n",
    "    \n",
    "    mlflow.spark.log_model(model_lr, \"logistic_regression_model\")\n",
    "    print(f\"Logistic Regression Logged. AUC: {auc_lr:.4f}\")\n",
    "\n",
    "# Random Forest\n",
    "with mlflow.start_run(run_name=\"Day7_Random_Forest\"):\n",
    "    model_rf = pipeline_rf.fit(train_df) \n",
    "    preds_rf = model_rf.transform(test_df)\n",
    "    auc_rf = evaluator.evaluate(preds_rf)\n",
    "    \n",
    "    # Logging Parameters & Metrics\n",
    "    mlflow.log_param(\"Model_Type\", \"Random Forest\")\n",
    "    mlflow.log_param(\"maxDepth\", 5) \n",
    "    mlflow.log_metric(\"AUC_Score\", auc_rf)\n",
    "    \n",
    "    mlflow.spark.log_model(model_rf, \"random_forest_model\")\n",
    "    print(f\"Random Forest Logged. AUC: {auc_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0db6d5a-5562-43b9-baaf-d3a79f0ee912",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day-7",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
