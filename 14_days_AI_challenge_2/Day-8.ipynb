{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c472a5e-b3af-4dee-ad97-9d92e329e455",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "df_silver = spark.table(\"workspace.ecommerce.user_features_silver\")\n",
    "\n",
    "df_features = df_silver.select(\"user_id\", \"total_views\", \"total_cart_adds\")\n",
    "df_labels = df_silver.select(\"user_id\", \"total_purchases\").withColumn(\"label\", when(col(\"total_purchases\") > 0, 1).otherwise(0)).drop(\"total_purchases\")\n",
    "df_model_ready = df_features.join(df_labels, on=\"user_id\", how=\"inner\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"total_views\", \"total_cart_adds\"], outputCol=\"features\")\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "pipeline_lr = Pipeline(stages=[assembler, lr])\n",
    "\n",
    "model_lr = pipeline_lr.fit(df_model_ready) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f720961-083a-464c-8ca7-8ee2ed279b3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql.functions import col, desc\n",
    "\n",
    "\n",
    "# Score all users\n",
    "predictions_df = model_lr.transform(df_silver)\n",
    "\n",
    "final_predictions = predictions_df.select(\n",
    "    \"user_id\",\n",
    "    \"total_views\",\n",
    "    \"total_cart_adds\",\n",
    "    \"total_purchases\",\n",
    "    col(\"prediction\").cast(\"int\").alias(\"predicted_to_buy\"),\n",
    "    vector_to_array(col(\"probability\"))[1].alias(\"buy_probability\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f197e704-5425-4d00-aad4-a7a40297a034",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save predictions to Gold Delta table\n",
    "gold_table_name = \"workspace.ecommerce.streaming_predictions_gold\" \n",
    "final_predictions.write.format(\"delta\").mode(\"overwrite\").saveAsTable(gold_table_name)\n",
    "\n",
    "# Identify top predicted buyers\n",
    "top_buyers = final_predictions.filter(\n",
    "    (col(\"predicted_to_buy\") == 1) & (col(\"total_purchases\") == 0)\n",
    ").orderBy(desc(\"buy_probability\"))\n",
    "\n",
    "print(\"\\nTop Predicted Future Buyers :\")\n",
    "display(top_buyers.limit(10))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day-8",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
